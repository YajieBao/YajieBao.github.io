\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe]{boyd2004convex}
S.~Boyd, S.~P. Boyd, and L.~Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Cai et~al.(2011)Cai, Liu, and Luo]{cai2011constrained}
T.~Cai, W.~Liu, and X.~Luo.
\newblock A constrained $\ell_{1}$ minimization approach to sparse precision
  matrix estimation.
\newblock \emph{Journal of the American Statistical Association}, 106\penalty0
  (494):\penalty0 594--607, 2011.

\bibitem[Chen et~al.(2012)Chen, Gittens, and Tropp]{chen2012masked}
R.~Y. Chen, A.~Gittens, and J.~A. Tropp.
\newblock The masked sample covariance estimator: an analysis using matrix
  concentration inequalities.
\newblock \emph{Information and Inference: A Journal of the IMA}, 1\penalty0
  (1):\penalty0 2--20, 2012.

\bibitem[De~Acosta et~al.(1981)]{de1981inequalities}
A.~De~Acosta et~al.
\newblock Inequalities for $ b $-valued random vectors with applications to the
  strong law of large numbers.
\newblock \emph{The Annals of Probability}, 9\penalty0 (1):\penalty0 157--161,
  1981.

\bibitem[Jin et~al.(2019)Jin, Netrapalli, Ge, Kakade, and Jordan]{jin2019short}
C.~Jin, P.~Netrapalli, R.~Ge, S.~M. Kakade, and M.~I. Jordan.
\newblock A short note on concentration inequalities for random vectors with
  subgaussian norm.
\newblock \emph{arXiv preprint arXiv:1902.03736}, 2019.

\bibitem[Jordan et~al.(2019)Jordan, Lee, and Yang]{jordan2019communication}
M.~I. Jordan, J.~D. Lee, and Y.~Yang.
\newblock Communication-efficient distributed statistical inference.
\newblock \emph{Journal of the American Statistical Association}, 114\penalty0
  (526):\penalty0 668--681, 2019.

\bibitem[Negahban et~al.(2012)Negahban, Ravikumar, Wainwright, Yu,
  et~al.]{negahban2012unified}
S.~N. Negahban, P.~Ravikumar, M.~J. Wainwright, B.~Yu, et~al.
\newblock A unified framework for high-dimensional analysis of $ m $-estimators
  with decomposable regularizers.
\newblock \emph{Statistical Science}, 27\penalty0 (4):\penalty0 538--557, 2012.

\bibitem[Vershynin(2018)]{vershynin2018high}
R.~Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge University Press, 2018.

\bibitem[Wainwright(2009)]{wainwright2009sharp}
M.~J. Wainwright.
\newblock Sharp thresholds for high-dimensional and noisy sparsity recovery
  using $\ell _{1}$-constrained quadratic programming (lasso).
\newblock \emph{IEEE transactions on information theory}, 55\penalty0
  (5):\penalty0 2183--2202, 2009.

\bibitem[Wainwright(2019)]{wainwright2019high}
M.~J. Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Zhang et~al.(2013)Zhang, Duchi, and
  Wainwright]{zhang2013communication}
Y.~Zhang, J.~C. Duchi, and M.~J. Wainwright.
\newblock Communication-efficient algorithms for statistical optimization.
\newblock \emph{The Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 3321--3363, 2013.

\end{thebibliography}
